{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zalecamy nie czytać notatników na githubie, ze względu na źle wyświetlające się wizualizacje i brak możliwości uruchamiania kodu. Polecamy otworzyć notatnik w google colab, następującym linkiem:\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/OlimpiadaAI/szkolenia/blob/edycja1/08_words_ngrams.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Słowa, tokanizacja, n-gramy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /home/witolddrzewakowski/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/witolddrzewakowski/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/witolddrzewakowski/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacja\n",
    "\n",
    "Współczesne modele językowe wykorzystują bardziej zaawansowane metody tokenizacji!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', 'Atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', '``', 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "example_text = \"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\"\n",
    "print(word_tokenize(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', 'Atlanta', \"'\", 's', 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.wordpunct_tokenize(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.regexp_tokenize(example_text, pattern=r'\\s+', gaps=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacja słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word        lower       lemma       stem        \n",
      "---         ---         ---         ---         \n",
      "The         the         The         the         \n",
      "quick       quick       quick       quick       \n",
      "brown       brown       brown       brown       \n",
      "fox         fox         fox         fox         \n",
      "jumps       jumps       jump        jump        \n",
      "over        over        over        over        \n",
      "the         the         the         the         \n",
      "lazy        lazy        lazy        lazi        \n",
      "dogs        dogs        dog         dog         \n"
     ]
    }
   ],
   "source": [
    "def normalize_word(word, mode=0):\n",
    "    if mode == 0:\n",
    "        normalized = word.lower()\n",
    "    elif mode == 1:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        normalized = lemmatizer.lemmatize(word)\n",
    "    elif mode == 2:\n",
    "        stemmer = nltk.PorterStemmer()\n",
    "        normalized = stemmer.stem(word)\n",
    "\n",
    "    return normalized\n",
    "\n",
    "\n",
    "print(f\"{'word':<12}{'lower':<12}{'lemma':<12}{'stem':<12}\")\n",
    "print(f\"{'---':<12}{'---':<12}{'---':<12}{'---':<12}\")\n",
    "for word in ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dogs']:\n",
    "    print(f\"{word:<12}\", end='')\n",
    "    for mode in [0, 1, 2]:\n",
    "        print(f\"{normalize_word(word, mode):<12}\" , end='')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n"
     ]
    }
   ],
   "source": [
    "example_brown_words = brown.words()[:20]\n",
    "print(example_brown_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gramy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The',),\n",
       " ('Fulton',),\n",
       " ('County',),\n",
       " ('Grand',),\n",
       " ('Jury',),\n",
       " ('said',),\n",
       " ('Friday',),\n",
       " ('an',),\n",
       " ('investigation',),\n",
       " ('of',),\n",
       " (\"Atlanta's\",),\n",
       " ('recent',),\n",
       " ('primary',),\n",
       " ('election',),\n",
       " ('produced',),\n",
       " ('``',),\n",
       " ('no',),\n",
       " ('evidence',),\n",
       " (\"''\",),\n",
       " ('that',)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(example_brown_words, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Fulton'),\n",
       " ('Fulton', 'County'),\n",
       " ('County', 'Grand'),\n",
       " ('Grand', 'Jury'),\n",
       " ('Jury', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'an'),\n",
       " ('an', 'investigation'),\n",
       " ('investigation', 'of'),\n",
       " ('of', \"Atlanta's\"),\n",
       " (\"Atlanta's\", 'recent'),\n",
       " ('recent', 'primary'),\n",
       " ('primary', 'election'),\n",
       " ('election', 'produced'),\n",
       " ('produced', '``'),\n",
       " ('``', 'no'),\n",
       " ('no', 'evidence'),\n",
       " ('evidence', \"''\"),\n",
       " (\"''\", 'that')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(example_brown_words, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Fulton', 'County'),\n",
       " ('Fulton', 'County', 'Grand'),\n",
       " ('County', 'Grand', 'Jury'),\n",
       " ('Grand', 'Jury', 'said'),\n",
       " ('Jury', 'said', 'Friday'),\n",
       " ('said', 'Friday', 'an'),\n",
       " ('Friday', 'an', 'investigation'),\n",
       " ('an', 'investigation', 'of'),\n",
       " ('investigation', 'of', \"Atlanta's\"),\n",
       " ('of', \"Atlanta's\", 'recent'),\n",
       " (\"Atlanta's\", 'recent', 'primary'),\n",
       " ('recent', 'primary', 'election'),\n",
       " ('primary', 'election', 'produced'),\n",
       " ('election', 'produced', '``'),\n",
       " ('produced', '``', 'no'),\n",
       " ('``', 'no', 'evidence'),\n",
       " ('no', 'evidence', \"''\"),\n",
       " ('evidence', \"''\", 'that')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(example_brown_words, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Najprostszy model językowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel:\n",
    "    def __init__(self, n, words):\n",
    "       self.n = n\n",
    "       self.words = self.normalize_words(words)\n",
    "       self.next_words = self.count_next_words()\n",
    "       self.probabilities = self.calculate_probabilities()\n",
    "\n",
    "    def normalize_words(self, words):\n",
    "        return [word.lower() for word in words]\n",
    "\n",
    "    def count_next_words(self):\n",
    "        next_words = defaultdict(Counter)\n",
    "        for ngram in ngrams(self.words, self.n + 1):\n",
    "            prefix = ngram[:-1]\n",
    "            next_word = ngram[-1]\n",
    "            next_words[prefix][next_word] += 1\n",
    "        return next_words\n",
    "   \n",
    "    def calculate_probabilities(self):\n",
    "        probabilities = {}\n",
    "        for prefix, words_count in self.next_words.items():\n",
    "            words, counts = zip(*words_count.items())\n",
    "            probabilities[prefix] = (words, np.array(counts) / sum(counts))\n",
    "        return probabilities\n",
    "\n",
    "    def generate(self, text, num_words=1):\n",
    "        out = text.copy()\n",
    "        for i in range(num_words):\n",
    "            prefix = tuple(out[-(self.n):])\n",
    "            next_word = self.sample_word(prefix)\n",
    "            out += [next_word]\n",
    "        return \" \".join(out)\n",
    "   \n",
    "    def sample_word(self, prefix):\n",
    "        words, probs = self.probabilities[prefix]\n",
    "        return np.random.choice(words, p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the best interest of commerce is expected to face is expected for night in expense allowances . georgia house hopper friday , the jury said that none of possible `` there to work toward adjournment . the validity of $50 million to make'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_words = brown.words()[:2000]\n",
    "model = NGramModel(1, brown_words)\n",
    "model.generate(['In', 'the', 'best', 'interest'], 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the best interest of both governments '' . merger proposed however , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' . the city purchasing department , the\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_words = brown.words()[:2000]\n",
    "model = NGramModel(3, brown_words)\n",
    "model.generate(['In', 'the', 'best', 'interest'], 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
